{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dVfaLrjLvxvQ"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Neural Networks\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 1*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wxtoY12mwmih"
   },
   "source": [
    "Source: https://machinelearningmastery.com/neural-networks-crash-course/\n",
    "\n",
    "## Define the Following:\n",
    "You can add image, diagrams, whatever you need to ensure that you understand the concepts below.\n",
    "\n",
    "### Input Layer:\n",
    "\n",
    "> Input layer, or the visible layer receives input from a dataset. This layer simply pass the input value though to the next layer.\n",
    "\n",
    "### Hidden Layer:\n",
    "\n",
    "> Not directly exposed to the input layer, in which they cannot be accessed except through the input layer.  We do not interact with them as they perform their functions. \n",
    "\n",
    "### Output Layer:\n",
    "\n",
    "> The output layer is the final layer. The purpose is to output a value or vector in respect to the problem being solved. This layer is transformed by the \"activation function\" into a readable format for the context presented. \n",
    "\n",
    "### Neuron:\n",
    "\n",
    "> The building blocks for NN. Neurons are simple computational units that have weighted input signals and produces an output signal using an activation function.\n",
    "\n",
    "### Weight:\n",
    "\n",
    "> Weight is the paramater within a NN that transforms input data within the networks hidden layer. For example, a single node may take the input data and multiply it by an assigned weight value, then add a bias before passing data to the next layer. \n",
    "\n",
    "### Activation Function:\n",
    "\n",
    "> An activation function is a mapping of summed weighted input to the output of the neuron. This function governs the threshold on which the neuron is activated.\n",
    "\n",
    "### Node Map:\n",
    "\n",
    "> A visual representation of the internal architecture of a neural network; i.e. a map of the nodes (neurons) in the network and how they are connected to and share information with one another.\n",
    "\n",
    "### Perceptron:\n",
    "\n",
    "> The idea of the Perceptron is inspired by the information processing of a single neural cell called a neuron. \n",
    "  A neuron accepts input signals via its dentrites, which pass the electrical signal down to the cell body. \n",
    "  In a similar way, the Perceptron receives input signals from examples of training data that we weight and combined in a linear equation called the activator. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NXuy9WcWzxa4"
   },
   "source": [
    "## Inputs -> Outputs\n",
    "\n",
    "### Explain the flow of information through a neural network from inputs to outputs. Be sure to include: inputs, weights, bias, and activation functions. How does it all flow from beginning to end?\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PlSwIJMC0A8F"
   },
   "source": [
    "#### Your Answer Here\n",
    "\n",
    "\n",
    "> Input units receive various forms of information from the outside world. This in turn, triggers the hidden units(layers). The hidden layers in turn multiplies the inputs by the weights of the connection they travel along, and each unit is summed up along the way. If the sum reaches a certain threshold value, the unit 'fires' and triggers the units its connected to (going right). Finaly the information arrives to the output units. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6sWR43PTwhSk"
   },
   "source": [
    "## Write your own perceptron code that can correctly classify (99.0% accuracy) a NAND gate. \n",
    "\n",
    ">  a NAND gate (NOT-AND) is a logic gate which produces an output which is false only if all its inputs are true; thus its output is complement to that of an AND gate. \n",
    "\n",
    "The NAND gate (negated AND) gives an output of 0 if both inputs are 1, it gives 1 otherwise.\n",
    "\n",
    "| x1 | x2 | y |\n",
    "|----|----|---|\n",
    "| 0  | 0  | 1 |\n",
    "| 1  | 0  | 1 |\n",
    "| 0  | 1  | 1 |\n",
    "| 1  | 1  | 0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = { 'x1': [0,1,0,1],\n",
    "         'x2': [0,0,1,1],\n",
    "         'y':  [1,1,1,0]\n",
    "       }\n",
    "\n",
    "df = pd.DataFrame.from_dict(data).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1  x2  y\n",
       "0   0   0  1\n",
       "1   1   0  1\n",
       "2   0   1  1\n",
       "3   1   1  0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sgh7VFGwnXGH"
   },
   "outputs": [],
   "source": [
    "# Establish training data\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Input\n",
    "# NAND gate features\n",
    "X = np.array([[0,0],\n",
    "              [1,0],\n",
    "              [0,1],\n",
    "              [1,1]], dtype=float)\n",
    "\n",
    "# Outputs\n",
    "# 0 if both inputs are 1, 1 otherwise.\n",
    "y = np.array([[1],\n",
    "              [1],\n",
    "              [1],\n",
    "              [0]], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid activation function and its derivative for updating weights\n",
    "\n",
    "def sigmoid(X: float) -> float:\n",
    "    return 1 / (1 + np.exp(-X))\n",
    "\n",
    "\n",
    "def sigmoid_derivative(X: float) -> float:\n",
    "    return sigmoid(X) * (1 - sigmoid(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random weights btw 0 and 1 for two inputs\n",
    "\n",
    "w = 2 * np.random.random((2,1)) - 1\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate weighted sum of inputs and weights\n",
    "z = np.dot(X, w)\n",
    "\n",
    "# Output the activated value for the end of 1 training epoch\n",
    "sigmoid(z)\n",
    "print(sigmoid(z))\n",
    "\n",
    "output = sigmoid(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = y - output\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjustments = error * sigmoid_derivative(output)\n",
    "adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with the adjustments determined, we can apply them to our original weights\n",
    "w += np.dot(X.T,adjustments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bringing it all together\n",
    "\n",
    "inputs = np.array([\n",
    "              [0,0,1],\n",
    "              [1,0,1],\n",
    "              [0,1,1],\n",
    "              [1,1,1]], dtype=float)\n",
    "\n",
    "# Outputs\n",
    "# 0 if both inputs are 1, 1 otherwise.\n",
    "correct_outputs = np.array([[1],\n",
    "                            [1],\n",
    "                            [1],\n",
    "                            [0]], dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generatings weights btw 0 and 1\n",
    "weights = 2 * np.random.random((3,1)) - 1\n",
    "\n",
    "# Sigmoid activation function and its derivative for updating weights\n",
    "\n",
    "def sigmoid(X: float) -> float:\n",
    "    return 1 / (1 + np.exp(-X))\n",
    "\n",
    "\n",
    "def sigmoid_derivative(X: float) -> float:\n",
    "    return sigmoid(X) * (1 - sigmoid(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights after training\n",
      "[[-11.84031106]\n",
      " [-11.84031106]\n",
      " [ 17.80933098]]\n",
      "Output after training\n",
      "[[0.99999998]\n",
      " [0.99744952]\n",
      " [0.99744952]\n",
      " [0.00281159]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#now we can iterate across this to increase our accuracy\n",
    "for iteration in range(10000):\n",
    "    \n",
    "    # Weighted sum of inputs / weights\n",
    "    weighted_sum = np.dot(inputs, weights)\n",
    "    \n",
    "    # Activate!\n",
    "    activated_output = sigmoid(weighted_sum)\n",
    "    \n",
    "    # Cac error\n",
    "    error = correct_outputs - activated_output\n",
    "    \n",
    "    adjustments = error * sigmoid_derivative(activated_output)\n",
    "    \n",
    "    # Update the Weights\n",
    "    weights += np.dot(inputs.T, adjustments)\n",
    "    \n",
    "print(\"Weights after training\")\n",
    "print(weights)\n",
    "\n",
    "print(\"Output after training\")\n",
    "print(activated_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xf7sdqVs0s4x"
   },
   "source": [
    "## Implement your own Perceptron Class and use it to classify a binary dataset: \n",
    "- [The Pima Indians Diabetes dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv) \n",
    "\n",
    "You may need to search for other's implementations in order to get inspiration for your own. There are *lots* of perceptron implementations on the internet with varying levels of sophistication and complexity. Whatever your approach, make sure you understand **every** line of your implementation and what its purpose is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv')\n",
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although neural networks can handle non-normalized data, scaling or normalizing your data will improve your neural network's learning speed. Try to apply the sklearn `MinMaxScaler` or `Normalizer` to your diabetes dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# pipe\n",
    "pipe = make_pipeline(\n",
    "    MinMaxScaler() # change values to be represented between 0 and 1\n",
    ")\n",
    "\n",
    "# split features and targets\n",
    "target = 'Outcome'\n",
    "X = diabetes.drop(target, axis=1)\n",
    "y = diabetes[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 8)\n",
      "(768,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape: (768, 8)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# apply pipe\n",
    "X = pipe.fit_transform(X)\n",
    "print(f\"\"\"X Shape: {X.shape}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cast y as np.array for modeling\n",
    "y = np.array(y)\n",
    "\n",
    "# reshape into a column vector, do the same for y_test if you want to evaluate on test set\n",
    "# https://stackoverflow.com/questions/17428621/python-differentiating-between-row-and-column-vectors\n",
    "y = y.reshape((-1,1))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducible work\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    sx = sigmoid(x)\n",
    "    return sx * (1-sx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = 2 * np.random.random((8,1)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(diabetes.columns) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.25091976],\n",
       "       [ 0.90142861],\n",
       "       [ 0.46398788],\n",
       "       [ 0.19731697],\n",
       "       [-0.68796272],\n",
       "       [-0.68801096],\n",
       "       [-0.88383278],\n",
       "       [ 0.73235229]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.72770517],\n",
       "       [ 0.4253715 ],\n",
       "       [ 0.62546723],\n",
       "       [ 0.28709139],\n",
       "       [-0.42362373],\n",
       "       [ 0.53403584],\n",
       "       [ 0.17043598],\n",
       "       [ 0.08789057]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_sum = np.dot(X, weights)\n",
    "print(weighted_sum.shape)\n",
    "weighted_sum[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.67430149],\n",
       "       [0.60476789],\n",
       "       [0.65146096],\n",
       "       [0.57128391],\n",
       "       [0.39564995],\n",
       "       [0.63042391],\n",
       "       [0.54250615],\n",
       "       [0.52195851]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activated_output = sigmoid(weighted_sum)\n",
    "print(activated_output.shape)\n",
    "activated_output[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.32569851],\n",
       "       [-0.60476789],\n",
       "       [ 0.34853904],\n",
       "       [-0.57128391],\n",
       "       [ 0.60435005],\n",
       "       [-0.63042391],\n",
       "       [ 0.45749385],\n",
       "       [-0.52195851],\n",
       "       [ 0.3047327 ],\n",
       "       [ 0.23904435]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = y - activated_output\n",
    "print(error.shape)\n",
    "error[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.07152958],\n",
       "       [-0.14455385],\n",
       "       [ 0.07913913],\n",
       "       [-0.13991806],\n",
       "       [ 0.14450679],\n",
       "       [-0.14688222],\n",
       "       [ 0.11354687],\n",
       "       [-0.13023795],\n",
       "       [ 0.06456393],\n",
       "       [ 0.04348268]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjustments = error * sigmoid_derivative(weighted_sum)\n",
    "print(adjustments.shape)\n",
    "adjustments[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ -7.10068393],\n",
       "       [-20.90491981],\n",
       "       [-24.93214537],\n",
       "       [ -7.91118561],\n",
       "       [ -3.12125496],\n",
       "       [-19.20088876],\n",
       "       [ -5.70916108],\n",
       "       [ -5.39533818]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights += np.dot(X.T, adjustments)\n",
    "print(weights.shape)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 768)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights after training\n",
      "[[ -7.10057238]\n",
      " [-20.90488362]\n",
      " [-24.93214537]\n",
      " [ -7.91118561]\n",
      " [ -3.12125496]\n",
      " [-19.20088734]\n",
      " [ -5.70914668]\n",
      " [ -5.39530562]]\n",
      "Output after training\n",
      "[[4.62607167e-22]\n",
      " [1.23390019e-15]\n",
      " [3.67844445e-20]\n",
      " [2.31907797e-15]\n",
      " [3.55757796e-20]\n",
      " [3.71487252e-17]\n",
      " [9.55603624e-15]\n",
      " [1.51649789e-12]\n",
      " [7.59146676e-24]\n",
      " [7.48059849e-18]\n",
      " [8.84721377e-20]\n",
      " [1.72844222e-22]\n",
      " [3.36914518e-22]\n",
      " [1.42414757e-22]\n",
      " [1.87464344e-21]\n",
      " [3.80474917e-11]\n",
      " [3.78918322e-22]\n",
      " [1.06045237e-17]\n",
      " [1.10718970e-15]\n",
      " [9.06503025e-19]\n",
      " [2.07299462e-22]\n",
      " [5.21058156e-20]\n",
      " [4.76812750e-25]\n",
      " [3.24473773e-20]\n",
      " [7.11639948e-25]\n",
      " [2.53196006e-20]\n",
      " [2.15469425e-21]\n",
      " [2.72509868e-15]\n",
      " [3.72891588e-22]\n",
      " [2.59433230e-20]\n",
      " [1.17203168e-20]\n",
      " [6.94152265e-22]\n",
      " [3.19085251e-14]\n",
      " [4.85471394e-17]\n",
      " [6.23407963e-21]\n",
      " [2.54600877e-17]\n",
      " [8.48711165e-21]\n",
      " [9.95880424e-21]\n",
      " [4.04392094e-18]\n",
      " [3.09632104e-22]\n",
      " [9.09578044e-21]\n",
      " [8.55471081e-22]\n",
      " [1.15501054e-19]\n",
      " [9.42141358e-29]\n",
      " [2.63171078e-19]\n",
      " [1.90315796e-23]\n",
      " [4.67341632e-17]\n",
      " [1.55486004e-15]\n",
      " [3.40061664e-19]\n",
      " [3.82281417e-07]\n",
      " [4.15780872e-16]\n",
      " [3.29464779e-14]\n",
      " [6.18868535e-16]\n",
      " [6.69869178e-26]\n",
      " [1.63511161e-22]\n",
      " [4.62544987e-12]\n",
      " [4.68242523e-24]\n",
      " [1.68443193e-22]\n",
      " [2.12356809e-22]\n",
      " [3.81920527e-18]\n",
      " [3.67822354e-05]\n",
      " [1.24724089e-19]\n",
      " [2.24593650e-13]\n",
      " [5.50180040e-18]\n",
      " [3.84297547e-18]\n",
      " [8.04891642e-18]\n",
      " [4.46984391e-20]\n",
      " [1.23531249e-21]\n",
      " [1.78518234e-14]\n",
      " [1.06874315e-20]\n",
      " [1.51923855e-17]\n",
      " [3.39021209e-19]\n",
      " [1.43666243e-23]\n",
      " [1.06533807e-20]\n",
      " [1.45975113e-16]\n",
      " [4.89860124e-09]\n",
      " [6.53281292e-17]\n",
      " [9.88041396e-19]\n",
      " [1.80406075e-12]\n",
      " [2.75296247e-16]\n",
      " [1.13688616e-13]\n",
      " [1.57258258e-04]\n",
      " [1.11748016e-18]\n",
      " [2.43718036e-15]\n",
      " [2.57153814e-24]\n",
      " [8.45394279e-19]\n",
      " [8.91207387e-22]\n",
      " [6.57768822e-18]\n",
      " [1.06098048e-22]\n",
      " [5.49337333e-16]\n",
      " [5.28645076e-12]\n",
      " [7.74665306e-20]\n",
      " [6.75257353e-21]\n",
      " [1.20032950e-18]\n",
      " [2.29689687e-19]\n",
      " [3.21434804e-21]\n",
      " [7.34865698e-16]\n",
      " [5.48468773e-12]\n",
      " [1.40691288e-15]\n",
      " [2.06032332e-23]\n",
      " [2.92023008e-21]\n",
      " [1.64006692e-16]\n",
      " [6.10797619e-18]\n",
      " [2.53671172e-15]\n",
      " [8.56515166e-17]\n",
      " [3.29517714e-17]\n",
      " [2.85962835e-19]\n",
      " [7.06019729e-19]\n",
      " [5.30623243e-16]\n",
      " [1.78887778e-18]\n",
      " [3.30332408e-21]\n",
      " [3.84796457e-22]\n",
      " [4.98351879e-17]\n",
      " [3.90374900e-15]\n",
      " [1.63581876e-20]\n",
      " [3.31667870e-22]\n",
      " [6.73783439e-19]\n",
      " [2.09041580e-14]\n",
      " [6.24601632e-16]\n",
      " [2.36356077e-16]\n",
      " [1.86900576e-24]\n",
      " [1.79386819e-18]\n",
      " [2.44126195e-18]\n",
      " [4.47885351e-20]\n",
      " [4.69050601e-17]\n",
      " [1.12741989e-16]\n",
      " [2.70469057e-20]\n",
      " [3.00105854e-17]\n",
      " [1.70484618e-20]\n",
      " [9.63909098e-19]\n",
      " [9.01036118e-21]\n",
      " [1.34129441e-18]\n",
      " [2.76639334e-21]\n",
      " [1.61821194e-19]\n",
      " [1.87368845e-15]\n",
      " [1.22795490e-17]\n",
      " [7.33600209e-17]\n",
      " [2.14040956e-15]\n",
      " [1.45534463e-18]\n",
      " [2.75660082e-19]\n",
      " [3.48534140e-18]\n",
      " [1.39690766e-20]\n",
      " [5.74737424e-16]\n",
      " [2.23409438e-18]\n",
      " [7.80362640e-20]\n",
      " [2.33780963e-13]\n",
      " [3.20841713e-18]\n",
      " [1.04236623e-18]\n",
      " [2.56549885e-21]\n",
      " [1.94674345e-15]\n",
      " [7.57213720e-21]\n",
      " [3.83050611e-16]\n",
      " [1.37568951e-24]\n",
      " [3.60972744e-23]\n",
      " [1.49509078e-24]\n",
      " [2.42425823e-25]\n",
      " [1.53199022e-14]\n",
      " [8.34291846e-16]\n",
      " [3.21729432e-16]\n",
      " [4.01257728e-26]\n",
      " [3.74468916e-22]\n",
      " [1.81500291e-20]\n",
      " [1.74049285e-20]\n",
      " [3.96787203e-16]\n",
      " [1.42062682e-19]\n",
      " [3.51426256e-19]\n",
      " [5.15129832e-19]\n",
      " [8.13291288e-18]\n",
      " [5.07430013e-17]\n",
      " [3.79479316e-19]\n",
      " [2.87690097e-18]\n",
      " [2.37678909e-20]\n",
      " [2.43386655e-10]\n",
      " [1.71966932e-17]\n",
      " [1.39810885e-15]\n",
      " [9.95571775e-24]\n",
      " [1.23492273e-17]\n",
      " [5.72630301e-27]\n",
      " [8.31658889e-22]\n",
      " [2.95675355e-21]\n",
      " [3.33504368e-16]\n",
      " [1.04315798e-17]\n",
      " [6.97480274e-12]\n",
      " [4.69193220e-14]\n",
      " [8.43683556e-19]\n",
      " [8.39158103e-24]\n",
      " [2.40540835e-24]\n",
      " [1.00902054e-22]\n",
      " [6.94710101e-20]\n",
      " [6.27035227e-21]\n",
      " [1.02955067e-14]\n",
      " [4.97327935e-21]\n",
      " [8.54858093e-20]\n",
      " [1.18764859e-16]\n",
      " [1.51907601e-15]\n",
      " [1.33523737e-23]\n",
      " [5.56263076e-14]\n",
      " [9.64314572e-16]\n",
      " [3.46858047e-19]\n",
      " [3.32500480e-19]\n",
      " [3.11807587e-18]\n",
      " [6.62026430e-20]\n",
      " [5.89607821e-17]\n",
      " [2.21993473e-15]\n",
      " [1.36111919e-20]\n",
      " [1.30065031e-17]\n",
      " [6.05849594e-26]\n",
      " [3.15330860e-24]\n",
      " [2.15228238e-16]\n",
      " [1.77456340e-24]\n",
      " [1.07156879e-14]\n",
      " [1.33307880e-22]\n",
      " [1.55631425e-25]\n",
      " [8.87736998e-20]\n",
      " [3.63347843e-21]\n",
      " [2.17547047e-24]\n",
      " [8.33744261e-19]\n",
      " [2.36424457e-19]\n",
      " [4.33565505e-18]\n",
      " [2.83927785e-18]\n",
      " [2.98565795e-21]\n",
      " [9.70395718e-23]\n",
      " [2.54621327e-11]\n",
      " [4.90888309e-21]\n",
      " [1.09064225e-15]\n",
      " [3.75906036e-17]\n",
      " [7.72623013e-17]\n",
      " [6.06939876e-20]\n",
      " [1.56292127e-26]\n",
      " [4.51973583e-20]\n",
      " [1.13716256e-21]\n",
      " [8.58656212e-24]\n",
      " [2.86411810e-16]\n",
      " [4.74970918e-18]\n",
      " [1.00925730e-15]\n",
      " [1.10804586e-21]\n",
      " [6.45630581e-25]\n",
      " [5.08680294e-24]\n",
      " [4.43440381e-23]\n",
      " [2.85407242e-15]\n",
      " [2.53698779e-15]\n",
      " [1.30718484e-17]\n",
      " [5.72937904e-16]\n",
      " [7.08140375e-18]\n",
      " [2.39945627e-21]\n",
      " [7.67306860e-25]\n",
      " [5.44357422e-19]\n",
      " [2.00685144e-25]\n",
      " [3.84723778e-21]\n",
      " [3.75617262e-18]\n",
      " [7.92646132e-17]\n",
      " [2.31491703e-18]\n",
      " [3.36071436e-16]\n",
      " [1.43235845e-16]\n",
      " [1.74174835e-18]\n",
      " [1.26026133e-17]\n",
      " [2.94297369e-17]\n",
      " [7.93958517e-17]\n",
      " [2.97113927e-19]\n",
      " [2.07047867e-24]\n",
      " [2.48931085e-21]\n",
      " [2.17467962e-12]\n",
      " [8.81610038e-18]\n",
      " [3.63677169e-21]\n",
      " [3.01948569e-17]\n",
      " [2.54538573e-19]\n",
      " [1.35372746e-12]\n",
      " [3.07983527e-20]\n",
      " [4.09299102e-13]\n",
      " [1.29984332e-11]\n",
      " [1.62326125e-23]\n",
      " [6.64253115e-16]\n",
      " [1.51519196e-17]\n",
      " [2.28662361e-17]\n",
      " [8.89522395e-20]\n",
      " [1.38916056e-19]\n",
      " [7.93657934e-17]\n",
      " [4.57050113e-16]\n",
      " [1.31490592e-18]\n",
      " [2.40689923e-16]\n",
      " [7.44703693e-19]\n",
      " [1.02330703e-21]\n",
      " [1.72614659e-21]\n",
      " [7.35870082e-22]\n",
      " [7.11294668e-18]\n",
      " [6.82457178e-21]\n",
      " [1.88853419e-24]\n",
      " [1.98865360e-22]\n",
      " [1.57915130e-14]\n",
      " [1.02864578e-19]\n",
      " [3.96273121e-18]\n",
      " [1.07760300e-17]\n",
      " [2.06155686e-22]\n",
      " [1.34746707e-18]\n",
      " [3.89815627e-17]\n",
      " [8.25352643e-21]\n",
      " [6.33387644e-20]\n",
      " [1.10923814e-19]\n",
      " [8.60262831e-22]\n",
      " [7.31690348e-19]\n",
      " [1.62118446e-13]\n",
      " [1.29070459e-18]\n",
      " [5.41718424e-19]\n",
      " [1.45352470e-22]\n",
      " [3.13335759e-18]\n",
      " [3.74775073e-20]\n",
      " [2.23332322e-21]\n",
      " [6.92884992e-17]\n",
      " [6.92858510e-19]\n",
      " [2.29457274e-19]\n",
      " [1.19431887e-16]\n",
      " [8.64291346e-19]\n",
      " [2.17931075e-19]\n",
      " [9.48604571e-16]\n",
      " [1.41279023e-21]\n",
      " [7.83795157e-18]\n",
      " [2.43533647e-16]\n",
      " [1.58236658e-20]\n",
      " [4.88917714e-19]\n",
      " [4.78255379e-22]\n",
      " [9.86043771e-18]\n",
      " [3.37231826e-18]\n",
      " [1.81443281e-17]\n",
      " [4.43266716e-24]\n",
      " [1.77713806e-18]\n",
      " [8.34484357e-19]\n",
      " [7.05317679e-19]\n",
      " [4.90724903e-22]\n",
      " [1.33290649e-20]\n",
      " [1.54858417e-18]\n",
      " [6.14667986e-20]\n",
      " [3.70343652e-15]\n",
      " [1.69212744e-15]\n",
      " [9.85019511e-19]\n",
      " [1.73680254e-14]\n",
      " [3.06548599e-23]\n",
      " [4.56405929e-12]\n",
      " [1.10930711e-18]\n",
      " [2.98155181e-23]\n",
      " [1.40180398e-23]\n",
      " [2.40245758e-17]\n",
      " [4.33044431e-17]\n",
      " [1.67345676e-12]\n",
      " [7.74263226e-20]\n",
      " [2.59638773e-19]\n",
      " [2.52773387e-23]\n",
      " [2.43501088e-16]\n",
      " [1.12109308e-09]\n",
      " [3.47753416e-15]\n",
      " [7.55731098e-16]\n",
      " [1.78541312e-18]\n",
      " [1.43154086e-19]\n",
      " [9.93773437e-18]\n",
      " [4.96166807e-15]\n",
      " [4.08574582e-18]\n",
      " [8.33424671e-23]\n",
      " [4.72880637e-18]\n",
      " [2.18177005e-16]\n",
      " [1.01643537e-20]\n",
      " [6.17697965e-24]\n",
      " [2.51026978e-22]\n",
      " [1.55515107e-20]\n",
      " [4.94613908e-24]\n",
      " [4.38371585e-22]\n",
      " [4.46059803e-21]\n",
      " [4.53382960e-17]\n",
      " [6.52793410e-18]\n",
      " [2.12792432e-14]\n",
      " [5.86936391e-17]\n",
      " [2.10520911e-22]\n",
      " [5.83778404e-26]\n",
      " [1.75998545e-14]\n",
      " [4.72932613e-16]\n",
      " [3.24577886e-17]\n",
      " [1.43613036e-18]\n",
      " [2.25085094e-25]\n",
      " [1.55352165e-16]\n",
      " [1.00375973e-16]\n",
      " [7.93182041e-22]\n",
      " [2.98073807e-22]\n",
      " [4.39341281e-18]\n",
      " [5.23709173e-15]\n",
      " [7.49411216e-16]\n",
      " [9.02210255e-16]\n",
      " [3.68481829e-17]\n",
      " [1.10315214e-14]\n",
      " [1.12113974e-19]\n",
      " [1.39623977e-23]\n",
      " [1.17204932e-22]\n",
      " [6.42353063e-18]\n",
      " [7.83019346e-18]\n",
      " [3.83167876e-22]\n",
      " [5.45084384e-17]\n",
      " [1.80803024e-17]\n",
      " [7.88121466e-21]\n",
      " [1.62917226e-18]\n",
      " [1.12793050e-16]\n",
      " [2.24358071e-18]\n",
      " [2.47959050e-14]\n",
      " [4.96735992e-22]\n",
      " [6.38088886e-16]\n",
      " [6.83711945e-18]\n",
      " [5.65750227e-22]\n",
      " [3.07190001e-18]\n",
      " [6.57955166e-20]\n",
      " [3.12879990e-18]\n",
      " [5.67873195e-18]\n",
      " [5.47593689e-14]\n",
      " [7.82483296e-23]\n",
      " [1.27292957e-23]\n",
      " [3.76607862e-21]\n",
      " [1.22413071e-18]\n",
      " [1.51187380e-22]\n",
      " [2.63726978e-18]\n",
      " [1.30010183e-18]\n",
      " [3.44248030e-23]\n",
      " [1.35889422e-16]\n",
      " [2.52987024e-22]\n",
      " [8.36674694e-14]\n",
      " [9.91058630e-18]\n",
      " [4.02590349e-22]\n",
      " [6.67604482e-16]\n",
      " [2.86290009e-18]\n",
      " [5.70311804e-17]\n",
      " [8.11258090e-24]\n",
      " [9.42297746e-24]\n",
      " [2.32712094e-05]\n",
      " [2.42566083e-21]\n",
      " [1.62365198e-22]\n",
      " [4.76207537e-19]\n",
      " [1.78572327e-08]\n",
      " [1.56167216e-17]\n",
      " [7.59496737e-16]\n",
      " [1.12489164e-17]\n",
      " [4.43598076e-16]\n",
      " [7.09746638e-13]\n",
      " [1.38719690e-23]\n",
      " [2.31175716e-19]\n",
      " [2.11383949e-14]\n",
      " [3.70513245e-20]\n",
      " [7.20714735e-25]\n",
      " [4.26784049e-16]\n",
      " [5.28526698e-18]\n",
      " [1.66491241e-18]\n",
      " [4.52132478e-17]\n",
      " [4.35286910e-28]\n",
      " [2.02275269e-16]\n",
      " [7.21757541e-19]\n",
      " [3.28387682e-17]\n",
      " [1.06447867e-17]\n",
      " [5.30227130e-14]\n",
      " [1.41315228e-17]\n",
      " [8.52191996e-18]\n",
      " [9.60315479e-12]\n",
      " [7.63679335e-17]\n",
      " [8.93874942e-23]\n",
      " [2.00844808e-17]\n",
      " [7.51142817e-17]\n",
      " [1.29293943e-25]\n",
      " [3.01017879e-22]\n",
      " [2.07247436e-19]\n",
      " [6.52253630e-13]\n",
      " [5.49143690e-19]\n",
      " [7.39522563e-18]\n",
      " [5.64875011e-21]\n",
      " [4.44718544e-15]\n",
      " [8.08974244e-13]\n",
      " [1.59458421e-17]\n",
      " [3.72246130e-12]\n",
      " [6.76809851e-24]\n",
      " [4.14038896e-22]\n",
      " [9.03299689e-19]\n",
      " [5.29225922e-18]\n",
      " [3.54559656e-21]\n",
      " [4.30256621e-16]\n",
      " [2.08323583e-20]\n",
      " [5.10736922e-20]\n",
      " [1.81444196e-18]\n",
      " [6.06883368e-20]\n",
      " [1.15532199e-21]\n",
      " [1.69016425e-21]\n",
      " [3.02824992e-20]\n",
      " [2.73657273e-15]\n",
      " [4.21025333e-18]\n",
      " [8.25791922e-14]\n",
      " [1.86096873e-20]\n",
      " [1.73584042e-20]\n",
      " [1.91085247e-25]\n",
      " [1.24191794e-16]\n",
      " [1.14040437e-23]\n",
      " [5.37383109e-17]\n",
      " [2.17771057e-19]\n",
      " [6.13771322e-18]\n",
      " [7.60927903e-20]\n",
      " [4.62705477e-05]\n",
      " [2.93908571e-21]\n",
      " [1.69882062e-16]\n",
      " [3.27942920e-16]\n",
      " [5.08682863e-23]\n",
      " [5.60221079e-22]\n",
      " [1.43850877e-18]\n",
      " [1.06230738e-17]\n",
      " [1.37608197e-15]\n",
      " [1.40982176e-18]\n",
      " [1.79048613e-19]\n",
      " [3.07952063e-18]\n",
      " [2.63639975e-23]\n",
      " [1.93904793e-17]\n",
      " [5.33435498e-15]\n",
      " [1.03472129e-19]\n",
      " [4.22417675e-19]\n",
      " [2.21954638e-16]\n",
      " [3.97202984e-17]\n",
      " [1.19638723e-14]\n",
      " [9.33827362e-15]\n",
      " [4.09342979e-20]\n",
      " [5.60612439e-24]\n",
      " [2.04674747e-21]\n",
      " [7.65761061e-17]\n",
      " [6.03715957e-21]\n",
      " [5.33785339e-15]\n",
      " [6.07148997e-20]\n",
      " [2.49965576e-07]\n",
      " [2.68309484e-20]\n",
      " [3.04639859e-16]\n",
      " [2.75487247e-14]\n",
      " [2.66970060e-14]\n",
      " [3.09572063e-17]\n",
      " [1.32220762e-17]\n",
      " [1.26794767e-15]\n",
      " [3.40874105e-17]\n",
      " [9.60857804e-19]\n",
      " [6.24227395e-19]\n",
      " [1.65285457e-10]\n",
      " [5.09641178e-16]\n",
      " [7.05265962e-12]\n",
      " [2.76068639e-18]\n",
      " [7.68398079e-14]\n",
      " [1.34039666e-20]\n",
      " [3.63833570e-23]\n",
      " [2.05755991e-21]\n",
      " [1.96960640e-19]\n",
      " [8.52238048e-22]\n",
      " [2.60360504e-19]\n",
      " [1.44477000e-17]\n",
      " [1.66916024e-25]\n",
      " [7.37038251e-26]\n",
      " [6.22570419e-19]\n",
      " [9.37377318e-23]\n",
      " [1.02106644e-25]\n",
      " [6.35927475e-17]\n",
      " [5.17163602e-17]\n",
      " [3.23036931e-20]\n",
      " [1.73618177e-15]\n",
      " [1.11804278e-16]\n",
      " [3.08202381e-19]\n",
      " [3.61194745e-18]\n",
      " [5.21188744e-19]\n",
      " [1.86076613e-21]\n",
      " [1.08780987e-17]\n",
      " [8.48828193e-20]\n",
      " [5.06578360e-23]\n",
      " [2.39352278e-17]\n",
      " [1.28151450e-16]\n",
      " [8.58187337e-17]\n",
      " [7.79074366e-15]\n",
      " [4.91074180e-18]\n",
      " [8.68337857e-18]\n",
      " [7.24579890e-21]\n",
      " [2.83692471e-18]\n",
      " [5.48764313e-16]\n",
      " [1.50041844e-18]\n",
      " [1.04678290e-16]\n",
      " [3.80469486e-16]\n",
      " [2.57843006e-21]\n",
      " [9.34307407e-17]\n",
      " [7.40263993e-16]\n",
      " [1.48255988e-19]\n",
      " [9.22606522e-19]\n",
      " [3.64257697e-26]\n",
      " [9.65213912e-23]\n",
      " [1.58433482e-16]\n",
      " [5.05974080e-21]\n",
      " [3.11331709e-19]\n",
      " [8.51219787e-22]\n",
      " [1.07064696e-13]\n",
      " [9.88246619e-20]\n",
      " [6.94157961e-16]\n",
      " [1.31327453e-24]\n",
      " [4.08936143e-07]\n",
      " [2.79927077e-24]\n",
      " [3.37981411e-20]\n",
      " [6.56307519e-20]\n",
      " [8.29938116e-16]\n",
      " [4.00697419e-21]\n",
      " [5.10057608e-22]\n",
      " [2.94631012e-17]\n",
      " [9.21732590e-12]\n",
      " [1.28938201e-20]\n",
      " [1.74520483e-13]\n",
      " [3.94271375e-18]\n",
      " [1.56533942e-09]\n",
      " [3.27112179e-18]\n",
      " [2.77030027e-23]\n",
      " [4.66059941e-14]\n",
      " [6.53188012e-18]\n",
      " [2.83011704e-24]\n",
      " [1.50674161e-14]\n",
      " [2.53112460e-22]\n",
      " [2.42551420e-15]\n",
      " [4.58541160e-16]\n",
      " [1.19070184e-20]\n",
      " [1.10538504e-25]\n",
      " [9.29222467e-20]\n",
      " [7.62049276e-23]\n",
      " [4.49178138e-16]\n",
      " [1.12637898e-19]\n",
      " [6.18651208e-13]\n",
      " [1.71908197e-21]\n",
      " [2.29384959e-10]\n",
      " [9.06479450e-21]\n",
      " [1.01088151e-17]\n",
      " [5.59838091e-26]\n",
      " [4.86096519e-18]\n",
      " [1.31042676e-15]\n",
      " [2.19889444e-20]\n",
      " [1.13990750e-15]\n",
      " [4.95551744e-18]\n",
      " [7.01518108e-20]\n",
      " [2.04050245e-15]\n",
      " [1.75331262e-17]\n",
      " [2.07645963e-18]\n",
      " [4.29793322e-15]\n",
      " [2.09978938e-18]\n",
      " [6.06178678e-16]\n",
      " [3.59662880e-19]\n",
      " [1.16843910e-17]\n",
      " [1.83361352e-17]\n",
      " [8.93870793e-21]\n",
      " [2.67028940e-15]\n",
      " [2.67132079e-18]\n",
      " [4.01810577e-18]\n",
      " [1.58620229e-20]\n",
      " [5.43184658e-10]\n",
      " [5.33581568e-18]\n",
      " [4.78485563e-22]\n",
      " [1.10631296e-19]\n",
      " [5.70171558e-20]\n",
      " [2.46591681e-22]\n",
      " [3.22396302e-15]\n",
      " [2.96104602e-14]\n",
      " [2.19759508e-17]\n",
      " [4.88418631e-20]\n",
      " [2.54582400e-15]\n",
      " [1.67818511e-17]\n",
      " [1.02595421e-19]\n",
      " [4.93183257e-15]\n",
      " [3.12171118e-22]\n",
      " [4.63313513e-24]\n",
      " [3.71939372e-19]\n",
      " [3.15262543e-22]\n",
      " [5.47640576e-25]\n",
      " [8.54045591e-27]\n",
      " [6.35870866e-24]\n",
      " [7.57688706e-19]\n",
      " [1.76329423e-19]\n",
      " [4.34491941e-22]\n",
      " [5.57094676e-19]\n",
      " [2.43262303e-18]\n",
      " [2.23378472e-22]\n",
      " [2.10193216e-22]\n",
      " [1.41221553e-14]\n",
      " [1.42190199e-21]\n",
      " [2.29420176e-25]\n",
      " [2.09359633e-20]\n",
      " [2.02871509e-21]\n",
      " [1.33330550e-21]\n",
      " [4.93113340e-15]\n",
      " [4.34853436e-16]\n",
      " [1.63698134e-15]\n",
      " [5.66130944e-13]\n",
      " [8.96308212e-23]\n",
      " [3.77845039e-18]\n",
      " [5.47109158e-19]\n",
      " [1.38385369e-17]\n",
      " [1.34316026e-19]\n",
      " [4.84205184e-16]\n",
      " [7.97077991e-15]\n",
      " [6.39485454e-19]\n",
      " [1.28498267e-23]\n",
      " [1.50820628e-18]\n",
      " [9.35594642e-27]\n",
      " [7.05853098e-20]\n",
      " [7.63756999e-22]\n",
      " [1.02256211e-13]\n",
      " [9.37512187e-23]\n",
      " [1.02493958e-20]\n",
      " [1.41964618e-08]\n",
      " [8.48393700e-21]\n",
      " [1.19747318e-19]\n",
      " [9.61677359e-20]\n",
      " [1.48309842e-20]\n",
      " [7.97107776e-24]\n",
      " [8.85139131e-13]\n",
      " [7.08435972e-18]\n",
      " [3.87144481e-19]\n",
      " [2.47877053e-08]\n",
      " [1.19418821e-16]\n",
      " [7.49911170e-22]\n",
      " [8.23490350e-18]\n",
      " [1.86952406e-19]\n",
      " [4.43435979e-20]\n",
      " [2.40070775e-21]\n",
      " [1.01764696e-16]\n",
      " [1.23985251e-16]\n",
      " [2.98742855e-22]\n",
      " [2.85159554e-23]\n",
      " [1.25219690e-18]\n",
      " [6.29297092e-18]\n",
      " [1.07880036e-19]\n",
      " [6.21750386e-18]\n",
      " [1.70544522e-18]\n",
      " [1.06522177e-19]\n",
      " [1.12362170e-21]\n",
      " [1.58582429e-19]\n",
      " [1.33707302e-20]\n",
      " [1.67388298e-19]\n",
      " [5.86462133e-20]\n",
      " [4.96006245e-20]\n",
      " [9.51368645e-14]\n",
      " [2.40367273e-19]\n",
      " [4.80034799e-19]\n",
      " [1.45724121e-24]\n",
      " [4.15131476e-16]\n",
      " [3.42595647e-17]\n",
      " [4.10905512e-17]\n",
      " [4.18508503e-19]\n",
      " [1.11016975e-17]\n",
      " [1.00825410e-16]\n",
      " [4.37315634e-18]\n",
      " [7.00682060e-24]\n",
      " [4.88243438e-15]\n",
      " [1.43664984e-15]\n",
      " [8.74849691e-23]\n",
      " [2.71701975e-26]\n",
      " [2.25735771e-21]\n",
      " [4.88537479e-24]\n",
      " [6.02510551e-20]\n",
      " [1.47555003e-22]\n",
      " [5.75185868e-19]\n",
      " [5.91303269e-19]\n",
      " [3.88727093e-20]\n",
      " [4.48848229e-16]\n",
      " [7.22845769e-25]\n",
      " [1.37870435e-22]\n",
      " [2.76420251e-22]\n",
      " [1.14325773e-22]\n",
      " [1.21852334e-18]\n",
      " [1.80228219e-17]\n",
      " [4.97960204e-25]\n",
      " [1.77804082e-15]\n",
      " [1.98014747e-24]\n",
      " [2.96320085e-15]\n",
      " [1.12555206e-21]\n",
      " [6.86279475e-19]\n",
      " [2.63342434e-18]\n",
      " [5.03540353e-17]\n",
      " [1.51414056e-16]]\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(10000):\n",
    "    \n",
    "    # Weighted sum of inputs / weights\n",
    "    weighted_sum = np.dot(X, weights)\n",
    "    \n",
    "    # Activate!\n",
    "    activated_output = sigmoid(weighted_sum)\n",
    "    \n",
    "    # Cac error\n",
    "    error = y - activated_output\n",
    "    \n",
    "    adjustments = error * sigmoid_derivative(weighted_sum)\n",
    "    \n",
    "    # Update the Weights\n",
    "    weights += np.dot(X.T, adjustments)\n",
    "    \n",
    "print(\"Weights after training\")\n",
    "print(weights)\n",
    "\n",
    "print(\"Output after training\")\n",
    "print(activated_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull values out of lists and append into a single list with a for loop\n",
    "pred = []\n",
    "for x in activated_output:\n",
    "  for x in x:\n",
    "    pred.append(int(round(x,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change values to 1 or 0 depending on the threshold (0.5) with a single nested list comprehension if not using for loop\n",
    "y_pred = [1 if x > 0.5 else 0 for x in [x for x in activated_output]]\n",
    "\n",
    "# Use np.where to define a condition and the desired outputs, like using an if/else\n",
    "# https://docs.scipy.org/doc/numpy/reference/generated/numpy.where.html\n",
    "y_pred = np.where(activated_output > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6510416666666666"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-W0tiX1F1hh2"
   },
   "outputs": [],
   "source": [
    "class Perceptron(object):\n",
    "    \n",
    "    def __init__(self, rate = 0.01, niter = 10):\n",
    "        self.rate = rate\n",
    "        self.niter = niter\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit training data\n",
    "        X : Training vectors, X.shape : [#samples, #features]\n",
    "        y : Target values, y.shape : [#samples]\n",
    "        \"\"\"\n",
    "\n",
    "        # weights\n",
    "        self.weight = np.zeros(1 + X.shape[1])\n",
    "\n",
    "        # Number of misclassifications\n",
    "        self.errors = []  # Number of misclassifications\n",
    "\n",
    "        for i in range(self.niter):\n",
    "          err = 0\n",
    "          for xi, target in zip(X, y):\n",
    "            delta_w = self.rate * (target - self.predict(xi))\n",
    "            self.weight[1:] += delta_w * xi\n",
    "            self.weight[0] += delta_w\n",
    "            err += int(delta_w != 0.0)\n",
    "          self.errors.append(err)\n",
    "        return self\n",
    "\n",
    "    def net_input(self, X):\n",
    "        \"\"\"Calculate net input\"\"\"\n",
    "        return np.dot(X, self.weight[1:]) + self.weight[0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unit step\"\"\"\n",
    "        \"\"\" Default Step Function\"\"\"\n",
    "        return np.where(self.net_input(X) >= 0.0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instance of the Class\n",
    "test = Perceptron()\n",
    "\n",
    "# Fit\n",
    "test.fit(X, y)\n",
    "\n",
    "# Predict (Returns a list of predictions)\n",
    "y_pred = test.predict(X)\n",
    "\n",
    "# Score\n",
    "accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6QR4oAW1xdyu"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Research \"backpropagation\" to learn how weights get updated in neural networks (tomorrow's lecture). \n",
    "- Implement a multi-layer perceptron. (for non-linearly separable classes)\n",
    "- Try and implement your own backpropagation algorithm.\n",
    "- What are the pros and cons of the different activation functions? How should you decide between them for the different layers of a neural network?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_431_Intro_to_NN_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
